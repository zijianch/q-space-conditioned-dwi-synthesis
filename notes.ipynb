{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discriminator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> $D$ takes $x=\\left(s_{b 0}, s_{T_2}, s_{T_1}, s_{b_i}\\right)$ as input, where $s_{b_i}$ is either sampled from a real dMRI or a generated image $G\\left(s_{b 0}, s_{T_2}, s_{T_1}, b_i\\right)$, and extracts a global representation $\\phi(x)$ via the encoding path $D_{\\text {enc }}$ to assess global realism. Additionally, a decoder $D_{d e c}$ expands $\\phi(x)$ to the input size and outputs per-pixel realism feedback. To incorporate $q$-space coordinates into the discriminator, a conditional projection via inner product is inserted before the last layer of both global and local branches following [22]. The final layer of $D$ is defined as $f(x, \\mathbf{b}):=\\mathbf{b}^{\\mathrm{T}} V \\boldsymbol{\\phi}(\\boldsymbol{x})+\\psi(\\boldsymbol{\\phi}(\\boldsymbol{x}))$, where $V$ is a learnable embedding of condition $\\mathbf{b} ; \\phi(x)$ is the output before conditioning, and $\\psi(\\cdot)$ is a scalar function of $\\phi(x)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discriminator code source: https://github.com/zijianch/q-space-conditioned-dwi-synthesis/blob/master/models/networks.py (starting from line 307)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet_Discriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, input_nc=1, ndf=64, kw=3, padw=1, n_layers=3, n_latent=2, output_nc=1, use_bias=True, embed=True, device='cuda:0'):\n",
    "        super(Unet_Discriminator, self).__init__()\n",
    "        self.conditional = embed\n",
    "        self.head = nn.Sequential(*[Conv2dBlock(input_nc, ndf, stride=1, kernel_size=kw, norm='sn', activation='lrelu', padding=padw),\n",
    "                    nn.LeakyReLU(0.2, True)])\n",
    "        nf_mult = 1\n",
    "        nf_mult_prev = 1\n",
    "        self.enc_layers = []\n",
    "        self.n_downsample = n_layers\n",
    "        for n in range(1, n_layers+1):  # gradually increase the number of filters\n",
    "            nf_mult_prev = nf_mult\n",
    "            nf_mult = min(2 ** n, 8)\n",
    "            self.enc_layers.append(nn.Sequential(*[\n",
    "                Conv2dBlock(ndf * nf_mult_prev, ndf * nf_mult, stride=1, kernel_size=kw, norm='sn', activation='lrelu',\n",
    "                            pad_type='zero', padding=padw),\n",
    "                nn.AvgPool2d(2),\n",
    "                nn.LeakyReLU(0.2, True)\n",
    "            ]))\n",
    "        self.enc_layers = nn.ModuleList(self.enc_layers)\n",
    "\n",
    "        self.latent = []\n",
    "        for i in range(n_latent):\n",
    "            self.latent +=[DResBlock(ndf * nf_mult, ndf * nf_mult, kw=kw, padding=padw),\n",
    "            nn.LeakyReLU(0.2, True)]\n",
    "        self.latent = nn.Sequential(*self.latent)\n",
    "        self.linear = nn.Linear(ndf * nf_mult, 1)\n",
    "\n",
    "        if embed:\n",
    "            self.embedding_middle = nn.Linear(4, ndf * nf_mult)\n",
    "            self.embedding_out = nn.Linear(4, output_nc)\n",
    "            self.fc = nn.Conv2d(1, ndf * nf_mult, 4, padding=1)\n",
    "        self.dec_layers = []\n",
    "        for n in range(1, n_layers+1):\n",
    "            nf_mult_prev = nf_mult\n",
    "            nf_mult = nf_mult // 2\n",
    "            self.dec_layers.append(nn.Sequential(*[\n",
    "                Conv2dBlock(ndf * (nf_mult_prev)* 2, ndf * nf_mult, stride=1, kernel_size=kw, norm='sn',\n",
    "                            activation='lrelu', pad_type='zero', padding=padw),\n",
    "                nn.LeakyReLU(0.2, True)\n",
    "            ]))\n",
    "        self.dec_layers = nn.ModuleList(self.dec_layers)\n",
    "        self.last = Conv2dBlock(ndf * nf_mult, 1, stride=1, kernel_size=kw, norm='sn',\n",
    "                            activation='none', pad_type='zero', padding=padw)\n",
    "\n",
    "    def init_weight(self):\n",
    "        def init_func(m):  # define the initialization function\n",
    "            classname = m.__class__.__name__\n",
    "            if hasattr(m, 'weight') and (classname.find('Conv') != -1 or classname.find('Linear') != -1):\n",
    "                torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "\n",
    "        return self.apply(init_func)\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        conditional = False\n",
    "        if y is not None:\n",
    "            conditional = True\n",
    "        h = x\n",
    "        res_features = []\n",
    "        h = self.head(h)\n",
    "        for n in range(self.n_downsample):\n",
    "            h = self.enc_layers[n](h)\n",
    "            res_features.append(h)\n",
    "        h = self.latent(h)\n",
    "        h_ = h\n",
    "        h_ = torch.sum(h_, [2,3])\n",
    "        bottleneck_out = self.linear(h_)\n",
    "\n",
    "        for n in range(self.n_downsample):\n",
    "            eid = -1 - n\n",
    "            h = torch.cat((res_features[eid], h), dim=1)\n",
    "            h = F.interpolate(h, scale_factor=2)\n",
    "            h = self.dec_layers[n](h)\n",
    "\n",
    "        out = self.last(h)\n",
    "        if conditional:\n",
    "            emb_mid = self.embedding_middle(y)\n",
    "            proj_mid = torch.sum(emb_mid * bottleneck_out, 1, keepdim=True)\n",
    "            bottleneck_out = bottleneck_out + proj_mid\n",
    "\n",
    "            emb_out = self.embedding_out(y)\n",
    "            emb_out = emb_out.view(emb_out.size(0), emb_out.size(1), 1, 1).expand_as(out)\n",
    "            proj = torch.sum(emb_out * out, 1, keepdim=True)\n",
    "            out = out + proj\n",
    "        return out, bottleneck_out\n",
    "\n",
    "    def gan_forward(self, input_real, real_img, real_bvec, input_fake, fake_img, fake_bvec):\n",
    "        fake_AB = torch.cat((input_fake, fake_img.detach()), dim=1)\n",
    "        real_AB = torch.cat((input_real, real_img), dim=1)\n",
    "        self.pred_fake_pix, pred_fake_img = self.forward(fake_AB, fake_bvec)\n",
    "        self.pred_real_pix, pred_real_img = self.forward(real_AB, real_bvec)\n",
    "\n",
    "\n",
    "    def get_D_loss(self, input_real, real_img, real_bvec, input_fake, fake_img, fake_bvec, criterionGAN):\n",
    "        \"\"\"Calculate GAN loss for the discriminator\"\"\"\n",
    "        #input: b0\n",
    "        #real_img: target dwi,\n",
    "        #real_bvec: bvec for real_img\n",
    "        #fake_img: generated image\n",
    "        #fake_bvec: bvec for generated img\n",
    "        #in case we want to use unpaired sampling, or the real_bvec & fake_bvec would be the same\n",
    "        # Fake; stop backprop to the generator by detaching fake_B\n",
    "        fake_AB = torch.cat((input_fake, fake_img.detach()), dim=1)\n",
    "        pred_fake_pix, pred_fake_img = self.forward(fake_AB, fake_bvec)\n",
    "        loss_D_fake_pix, loss_D_fake_img = criterionGAN(pred_fake_pix, False), criterionGAN(pred_fake_img, False)\n",
    "        # Real\n",
    "        real_AB = torch.cat((input_real, real_img), dim=1)\n",
    "        print(real_AB.size())\n",
    "        pred_real_pix, pred_real_img = self.forward(real_AB, real_bvec)\n",
    "        loss_D_real_pix, loss_D_real_img = criterionGAN(pred_real_pix, True), criterionGAN(pred_real_img, True)\n",
    "        # combine loss and calculate gradients\n",
    "        loss_D_global = (loss_D_fake_img + loss_D_real_img) * 0.5\n",
    "        loss_D_local = (loss_D_fake_pix + loss_D_real_pix) * 0.5\n",
    "\n",
    "        return loss_D_global, loss_D_local\n",
    "\n",
    "    def get_G_loss(self, input, fake_img, fake_emb, criterionGAN):\n",
    "        \"\"\"Calculate GAN loss for the generator\"\"\"\n",
    "        # G(A) should fake the discriminator\n",
    "        fake_AB = torch.cat((input, fake_img), dim=1)\n",
    "        pred_fake_pix, pred_fake_img = self.forward(fake_AB, fake_emb)\n",
    "        loss_G_global = criterionGAN(pred_fake_pix, True)\n",
    "        loss_G_local  = criterionGAN(pred_fake_img, True)\n",
    "        return loss_G_global, loss_G_local"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usage example: https://github.com/zijianch/q-space-conditioned-dwi-synthesis/blob/master/mains/trainer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dwi_Trainer(nn.Module):\n",
    "\n",
    "    def __init__(self, hyperparameters):\n",
    "        super(dwi_Trainer, self).__init__()\n",
    "        \n",
    "        ####### some parts of the code omitted  #######\n",
    "\n",
    "        self.gan_w = hyperparameters['gan_w'] #GAN weight\n",
    "\n",
    "        if self.gan_w > 0:\n",
    "            print('GAN with {} discriminator'.format(hyperparameters['dis']['d_type']))\n",
    "            self.dis_type = hyperparameters['dis']['d_type']\n",
    "            self.dis = Unet_Discriminator(hyperparameters['dis']['in_dim'], ndf=hyperparameters['dis']['dim'],\n",
    "                                          n_layers=hyperparameters['dis']['n_layer'], n_latent=2, embed=True, device=self.device)\n",
    "\n",
    "            ####### some parts of the code omitted  #######\n",
    "            \n",
    "        else:\n",
    "            self.dis_scheduler = None\n",
    "    \n",
    "        ####### some parts of the code omitted  #######\n",
    "        \n",
    "            \n",
    "    def update(self, data_dict, n_dwi,  iterations):\n",
    "        \n",
    "        ####### some parts of the code omitted  #######\n",
    "\n",
    "        i = 0\n",
    "        return_dict, in_i = self.prepare_input(data_dict, i)\n",
    "        cond_i = data_dict['cond_%d'%(i+1)].to(self.device).float()\n",
    "        dwi_i = data_dict['dwi_%d'%(i+1)].to(self.device).float()\n",
    "        pred_i = self.gen_a.forward(in_i, cond_i)\n",
    "        self.loss_dwi += self.l1_w * self.recon_criterion(pred_i, dwi_i, False)\n",
    "        total_loss = self.loss_dwi\n",
    "        if self.gan_w > 0:\n",
    "            if self.dis_type == 'unet':\n",
    "                self.loss_G_global, self.loss_G_local = self.dis.get_G_loss(in_i, pred_i, cond_i, self.criterionGAN)\n",
    "                self.loss_g += 0.5 * (self.loss_G_global + self.loss_G_local) * self.gan_w\n",
    "            else:\n",
    "                self.loss_g += self.dis.get_G_loss(in_i, pred_i, cond_i, self.criterionGAN)\n",
    "            self.set_requires_grad([self.dis], False)   # Ds require no gradients when optimizing Gs\n",
    "            self.set_requires_grad([self.gen_a], True)  # Ds require no gradients when optimizing Gs\n",
    "            total_loss += self.loss_g\n",
    "        total_loss.backward()\n",
    "        self.gen_opt.step()\n",
    "        return_dict['dwi'] = dwi_i[0,0].cpu().numpy()\n",
    "        bvec_vis = cond_i[0].cpu().numpy()\n",
    "        return_dict['pred%.1f,%.1f,%.1f[%.1f]'%(bvec_vis[0], bvec_vis[1], bvec_vis[2],bvec_vis[3])]= pred_i[0,0].detach().cpu().numpy()\n",
    "\n",
    "        if self.gan_w > 0:\n",
    "            if iterations %2 ==0:\n",
    "                self.set_requires_grad([self.dis], True)     # Ds require no gradients when optimizing Gs\n",
    "                self.set_requires_grad([self.gen_a], False)  # Ds require no gradients when optimizing Gs\n",
    "                self.dis_opt.zero_grad()\n",
    "                select_j_list = list(set(np.arange(n_dwi)) - {0})  # unpaired\n",
    "                j = select_j_list[np.random.randint(len(select_j_list))]\n",
    "                _, in_j = self.prepare_input(data_dict, j)\n",
    "                dwi_j = data_dict['dwi_%d' % (j + 1)].to(self.device).float()\n",
    "                cond_j = data_dict['cond_%d' % (j + 1)].to(self.device).float()\n",
    "                self.loss_D_global, self.loss_D_local = self.dis.get_D_loss(in_j, dwi_j, cond_j, in_i, pred_i, cond_i, self.criterionGAN)\n",
    "                print('Global D: {}, Local D: {}'.format(self.loss_D_global.item(), self.loss_D_local.item()))\n",
    "                self.loss_d = 0.5 * (self.loss_D_global + self.loss_D_local) * self.gan_w\n",
    "\n",
    "                self.loss_d.backward()\n",
    "                self.dis_opt.step()\n",
    "\n",
    "        return return_dict\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
